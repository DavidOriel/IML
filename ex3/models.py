import numpy as np
from math import log
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier


class Model():
    """
    general class for the fucntion score, every model will use the score function generated by that class.
    """

    def score(self, X, y,predicted):
        predicted = predicted.reshape(y.shape)
        num_samples = len(X)
        N = np.sum(y == -1)
        P = np.sum(y == 1)
        FP = y[np.where((y != predicted) & (y == -1))].shape[0]
        FN = y[np.where((y != predicted) & (y == 1))].shape[0]
        TP = y[np.where((y == predicted) & (y == 1))].shape[0]
        TN = y[np.where((y == predicted) & (y == -1))].shape[0]
        FPR = FP / N
        precision = TP / (TP + FP)
        recall = TP / P
        accuracy = (TN + TP) / num_samples
        error = (FP + FN) / num_samples
        return {"num_samples": num_samples, "error": error, "accuracy": accuracy, "FPR": FPR, "TPR": recall,
                 "precision":
                    precision,"recall": recall}

class Perceptron():
    """
    perceptron class
    """

    def __init__(self):
        self.model = None

    def iteration(self, x, y, w):
        for i in range(x.shape[1]):
            if (y[i] * w @ (x[:, i])) <= 0:
                return i

    def fit(self, X, y):
        X = X
        columns = len(X[0])
        w = np.zeros_like(X[:, 0])
        while True:
            index = self.iteration(X, y, w)
            if index is None:
                break
            w = w + y[index] * X[:, index]
        self.model = w

    def predict(self, X):
        p = (X@self.model >= 0).astype("int")
        return np.where(p == 0, -1, p)

    def score(self, X, y):
        predicted = self.predict(X)
        scored = Model().score(X, y, predicted)
        return scored


class LDA:
    """
    Linear Discriminent Analysis class
    """

    def __init__(self):
        self.model = 0

    def fit(self, X, y):
        X = X
        cov = np.cov(X)
        positive_num = np.sum(y == 1)
        negative_num = np.sum(y == -1)
        self.p_positive = positive_num / len(y)
        self.p_negative = negative_num / len(y)
        self.positive_mean = (X[:, np.where(y == 1)]).reshape(X.shape[0], positive_num).mean(axis=1)
        self.negative_mean = (X[:, np.where(y == -1)]).reshape(X.shape[0], negative_num).mean(axis=1)
        self.pinv = np.linalg.pinv(cov)
        self.pos = -0.5*self.positive_mean.T @ self.pinv @ self.positive_mean + log(self.p_positive)
        self.neg = -0.5*self.negative_mean @ self.pinv @ self.negative_mean + log(self.p_negative)


    def predict(self, X):
        deltaplus = X @ self.pinv @ self.positive_mean + self.pos
        deltaminus = X @ self.pinv @ self.negative_mean + self.neg
        self.predicted = np.array([])
        for i in range(len(deltaminus)):
            if deltaplus[i]>deltaminus[i]:
                self.predicted= np.append(self.predicted,1)
            else:
                self.predicted= np.append(self.predicted,-1)
        return self.predicted

    def score(self, X, y):
        predicted = self.predict(X)
        scored = Model().score(X, y, predicted)
        return scored


class SVM:
    """
    svm class
    """
    svm = SVC(C=1e10, kernel="linear")

    def __init__(self):
        self.model = 0
        self.svm = SVC(C=1e10, kernel="linear")

    def fit(self, X, y):
        self.model = self.svm.fit(X, y)

    def predict(self, X):
        return self.svm.predict(X)

    def score(self, X, y):
        predicted = self.predict(X)
        scored = Model().score(X, y, predicted)
        return scored


class Logistic:

    def __init__(self):
        self.logistic = LogisticRegression(solver="liblinear")
        self.model = 0

    def fit(self, X, y):
        self.model = self.logistic.fit(X, y)

    def predict(self, X):
        return self.logistic.predict(X)

    def score(self, X, y):
        predicted = self.predict(X)
        scored = Model().score(X, y, predicted)
        return scored


class DecisionTree:
    """
    decision tree classifier class
    """

    def __init__(self):
        self.tree = DecisionTreeClassifier(max_depth=3)
        self.model = 0

    def fit(self, X, y):
        self.model = self.tree.fit(X, y)

    def predict(self, X):
        return self.tree.predict(X)

    def score(self, X, y):
        predicted = self.predict(X)
        scored = Model().score(X, y, predicted)
        return scored


class K_nearest:
    """
    k-nearest neighbors class
    """

    def __init__(self):
        self.k = KNeighborsClassifier(n_neighbors=5)
        self.model = 0

    def fit(self, X, y):
        self.model = self.k.fit(X, y)

    def predict(self, X):
        return self.k.predict(X)

    def score(self, X, y):
        predicted = self.predict(X)
        scored = Model().score(X, y, predicted)
        return scored


class Soft_SVM:
    """
    soft svm class
    """
    svm = SVC(C=1, kernel="linear")

    def __init__(self):
        self.model = 0
        self.svm = SVC(C=1, kernel="linear")

    def fit(self, X, y):
        self.model = self.svm.fit(X, y)

    def predict(self, X):
        return self.svm.predict(X)

    def score(self, X, y):
        predicted = self.predict(X)
        scored = Model().score(X, y, predicted)
        return scored
